{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-31T10:24:21.803942Z","iopub.execute_input":"2022-12-31T10:24:21.804872Z","iopub.status.idle":"2022-12-31T10:24:21.809684Z","shell.execute_reply.started":"2022-12-31T10:24:21.804837Z","shell.execute_reply":"2022-12-31T10:24:21.808551Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#model.py\n\nimport torch.nn as nn\nimport torch\n\nclass AlexNet(nn.Module):\n    def __init__(self, num_classes=1000, init_weights=False):   \n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(  #打包\n            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2),  # input[3, 224, 224]  output[48, 55, 55] 自动舍去小数点后\n            nn.ReLU(inplace=True), #inplace 可以载入更大模型\n            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 27, 27] kernel_num为原论文一半\n            nn.Conv2d(48, 128, kernel_size=5, padding=2),           # output[128, 27, 27]\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 13, 13]\n            nn.Conv2d(128, 192, kernel_size=3, padding=1),          # output[192, 13, 13]\n            nn.ReLU(inplace=True),\n            nn.Conv2d(192, 192, kernel_size=3, padding=1),          # output[192, 13, 13]\n            nn.ReLU(inplace=True),\n            nn.Conv2d(192, 128, kernel_size=3, padding=1),          # output[128, 13, 13]\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6]\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=0.5),\n            #全链接\n            nn.Linear(128 * 6 * 6, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.5),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.5),\n            nn.Linear(2048, num_classes),\n        )\n        if init_weights:\n            self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, start_dim=1) #展平   或者view()\n        x = self.classifier(x)\n        return x\n             \nalexnet = AlexNet()\n# alexnet","metadata":{"execution":{"iopub.status.busy":"2022-12-31T10:24:24.278883Z","iopub.execute_input":"2022-12-31T10:24:24.279247Z","iopub.status.idle":"2022-12-31T10:24:26.213704Z","shell.execute_reply.started":"2022-12-31T10:24:24.279215Z","shell.execute_reply":"2022-12-31T10:24:26.212732Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\n\n#建立自己的dataset train_data\nclass MyDataset(Dataset):\n    def __init__(self, image_path: list, image_class: list, transform=None):\n        self.image_path = image_path\n        self.image_class = image_class\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_path)\n\n    def __getitem__(self, item):\n        img = Image.open(self.image_path[item]).convert('RGB')\n#         if img.mode != 'RGB':\n#             raise ValueError(\"image: {} isn't RGB mode\".format(self.image_path[item]))\n        label = self.image_class[item]\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2022-12-31T10:24:29.826828Z","iopub.execute_input":"2022-12-31T10:24:29.827324Z","iopub.status.idle":"2022-12-31T10:24:30.039538Z","shell.execute_reply.started":"2022-12-31T10:24:29.827289Z","shell.execute_reply":"2022-12-31T10:24:30.038553Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndef get_data(imgs, labels, val_rat=0.2):\n\n    train_imgs_path = []\n    train_labels = []\n    val_imgs_path = []\n    val_labels = []\n    supported = ['.jpg', '.JPG']\n\n    # 得到所有图片地址\n    images_name = os.listdir(imgs)\n    images = [os.path.join(imgs, img) for img in os.listdir(imgs)\n              if os.path.splitext(img)[-1] in supported]\n    # 得到所有图片label\n    df = pd.read_csv(labels)\n    path_label_dict = {}\n    for i in images_name:\n        path_label_dict.update({os.path.join(imgs, i): df[df.image_id == i].iloc[0, 1]})\n\n    # 按比例划分val\n    val_num = len(images) * val_rat\n    val_path = random.sample(images, int(val_num))\n\n    for img_path in images:\n        if img_path in val_path:\n            val_imgs_path.append(img_path)\n            val_labels.append(path_label_dict[img_path])\n        else:\n            train_imgs_path.append(img_path)\n            train_labels.append(path_label_dict[img_path])\n\n    print(\"{} images were found in the dataset\".format(len(images)))\n    print(\"{} in train_set\".format(len(train_labels)))\n    print(\"{} in val_set\".format(len(val_labels)))\n\n#     if plot:\n#         train_male_num = np.sum(np.array(train_labels) == 1)\n#         train_female_num = np.sum(np.array(train_labels) == 0)\n#         val_male_num = np.sum(np.array(val_labels) == 1)\n#         val_female_num = np.sum(np.array(val_labels) == 0)\n#         x = ['train_m', 'train_f', 'val_m', 'val_f']\n#         y = [train_male_num, train_female_num, val_male_num, val_female_num]\n#         plt.bar(x, y, color=['b', 'r', 'b', 'r'])\n#         for a, b, i in zip(x, y, range(len(x))):  # zip 函数\n#             plt.text(a, b, \"%d\" % y[i], ha='center', fontsize=12)  # plt.text 函数\n#         plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]  # 设置字体\n#         plt.title(\"数据集性别分布\")\n#         plt.show()\n\n    return train_imgs_path, train_labels, val_imgs_path, val_labels","metadata":{"execution":{"iopub.status.busy":"2022-12-31T10:24:35.356731Z","iopub.execute_input":"2022-12-31T10:24:35.357102Z","iopub.status.idle":"2022-12-31T10:24:35.368611Z","shell.execute_reply.started":"2022-12-31T10:24:35.357065Z","shell.execute_reply":"2022-12-31T10:24:35.367512Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_image_path= \"/kaggle/input/bitmoji-faces-gender-recognition/BitmojiDataset/trainimages/\"\ntrain_lable_path = \"/kaggle/input/bitmoji-faces-gender-recognition/train.csv\"\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224))\n])\n\ntrain_imgs, train_labels, val_imgs, val_labels = get_data(train_image_path, train_lable_path, val_rat=0.2)\ntrain_dataset = MyDataset(train_imgs, train_labels, transform)\nval_dataset = MyDataset(val_imgs, val_labels, transform)\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size)\nprint(train_loader)\nprint(val_loader)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T10:24:42.338614Z","iopub.execute_input":"2022-12-31T10:24:42.338966Z","iopub.status.idle":"2022-12-31T10:24:44.103108Z","shell.execute_reply.started":"2022-12-31T10:24:42.338933Z","shell.execute_reply":"2022-12-31T10:24:44.102131Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"3000 images were found in the dataset\n2400 in train_set\n600 in val_set\n<torch.utils.data.dataloader.DataLoader object at 0x7f2d37be6d90>\n<torch.utils.data.dataloader.DataLoader object at 0x7f2d37bc5b50>\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport os\nimport torch\n#train and val\ndef evaluate_accuracy(data_iter, net, device=None):\n    if device is None and isinstance(net, torch.nn.Module):\n        # 如果没指定device就使用net的device\n        device = list(net.parameters())[0].device\n    acc_sum, n = 0.0, 0\n    with torch.no_grad():\n        for X, y in data_iter:\n            y+=1\n            net.eval() # 评估模式, 这会关闭dropout\n            acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n            net.train() # 改回训练模式\n            n += y.shape[0]\n    return acc_sum / n\n\n\ndef train(net, train_iter, val_iter, batch_size, optimizer, device, num_epochs):\n    net = net.to(device)\n    print(\"training on \", device)\n    loss = torch.nn.CrossEntropyLoss()\n    loss.to(device)\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n        for X, y in train_iter:\n#             print(X)\n#             print(y)\n            y+=1\n#             print(y)\n            X = X.to(device)\n            y = y.to(device)\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            optimizer.zero_grad()\n            l.backward()\n            optimizer.step()\n            train_l_sum += l.cpu().item()\n            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n            n += y.shape[0]\n            batch_count += 1\n        val_acc = evaluate_accuracy(val_iter, net)\n        print('epoch %d, loss %.4f, train acc %.3f, val acc %.3f, time %.1f sec'\n              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, val_acc, time.time() - start))\n    print(\"train over!\")\n    if not os.path.exists('./model_save'): #判断所在目录下是否有该文件名的文件夹\n        os.mkdir(\"./model_save\")\n    torch.save(net.state_dict(), os.path.join(\"./model_save/\", \"epoch_{}_{}.pth\".format(epoch+1,1)))\n#     torch.save(net, \"./model_save/alexnet_epoch5.pth\") #保存模型\n\n    \n#     torch.save(net.state_dict(), os.path.join(\"./model_save/\", \"epoch5.pth\")) #保存模型\n#     print(alexnet)\n    print(\"model saved!\")\n    \n# model_save_path = \"./model_save\" \n# alexnet.to(device)\n# model = AlexNet()\n# model.to(device)\nlr, num_epochs = 0.01, 20\n# optimizer = torch.optim.Adam(alexnet.parameters(), lr=lr)\noptimizer = torch.optim.SGD(alexnet.parameters(), lr=lr) \ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ntrain(alexnet, train_loader, val_loader, batch_size, optimizer, device, num_epochs)\n\n# /kaggle/input/bitmoji-faces-gender-recognition/sample_submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-12-31T10:24:47.972022Z","iopub.execute_input":"2022-12-31T10:24:47.973231Z","iopub.status.idle":"2022-12-31T10:30:41.546515Z","shell.execute_reply.started":"2022-12-31T10:24:47.973187Z","shell.execute_reply":"2022-12-31T10:30:41.545338Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"training on  cuda:0\nepoch 1, loss 5.1288, train acc 0.482, val acc 0.530, time 35.4 sec\nepoch 2, loss 0.8818, train acc 0.474, val acc 0.530, time 16.1 sec\nepoch 3, loss 0.7195, train acc 0.520, val acc 0.615, time 16.8 sec\nepoch 4, loss 0.7365, train acc 0.512, val acc 0.530, time 16.9 sec\nepoch 5, loss 0.7275, train acc 0.533, val acc 0.640, time 16.5 sec\nepoch 6, loss 0.6845, train acc 0.585, val acc 0.883, time 16.6 sec\nepoch 7, loss 0.7662, train acc 0.617, val acc 0.850, time 16.9 sec\nepoch 8, loss 0.5445, train acc 0.748, val acc 0.920, time 16.6 sec\nepoch 9, loss 0.4541, train acc 0.864, val acc 0.528, time 16.4 sec\nepoch 10, loss 0.4880, train acc 0.867, val acc 0.932, time 16.8 sec\nepoch 11, loss 0.2455, train acc 0.922, val acc 0.935, time 16.5 sec\nepoch 12, loss 0.7277, train acc 0.858, val acc 0.943, time 16.5 sec\nepoch 13, loss 0.2061, train acc 0.932, val acc 0.958, time 16.5 sec\nepoch 14, loss 0.1865, train acc 0.944, val acc 0.962, time 16.9 sec\nepoch 15, loss 0.1729, train acc 0.950, val acc 0.967, time 16.3 sec\nepoch 16, loss 0.1603, train acc 0.954, val acc 0.980, time 16.6 sec\nepoch 17, loss 0.1462, train acc 0.961, val acc 0.977, time 16.3 sec\nepoch 18, loss 0.1426, train acc 0.962, val acc 0.983, time 16.5 sec\nepoch 19, loss 0.1289, train acc 0.965, val acc 0.982, time 16.3 sec\nepoch 20, loss 0.1123, train acc 0.970, val acc 0.985, time 16.5 sec\ntrain over!\nmodel saved!\n","output_type":"stream"}]},{"cell_type":"code","source":"model_path = '/kaggle/working/model_save/epoch_20_1.pth'\nalex_test = AlexNet()\nalex_test.load_state_dict(torch.load(model_path))\n\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224))\n])\n\ntestimages_path = \"/kaggle/input/bitmoji-faces-gender-recognition/BitmojiDataset/testimages\"\nsample_submission_path = \"/kaggle/input/bitmoji-faces-gender-recognition/sample_submission.csv\"\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(\"test on \"+str(device))\nalex_test.to(device)\n#数据\ndf = pd.read_csv(sample_submission_path)\n\nalex_test.eval()    #把模型转为test模式\ncnt = 0\n\nwith torch.no_grad():\n    imgs = os.listdir(testimages_path)\n    imgs.sort()\n    for img_name in imgs:\n        img_path = os.path.join(testimages_path, img_name)\n        img = Image.open(img_path).convert('RGB')\n        img = transform(img)\n        img = img.to(device).unsqueeze(0)\n        pred = int(alex_test(img).argmax(1))\n        df.iloc[cnt, 1] = -1 if pred == 0 else 1\n        cnt += 1\n#     df = df.iloc[:,[0, 2]]\n    df.to_csv(\"./sample_submission.csv\")\n    print(\"test over!\")\n# df.drop(columns=\" \",axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T10:33:45.141754Z","iopub.execute_input":"2022-12-31T10:33:45.142147Z","iopub.status.idle":"2022-12-31T10:33:56.673590Z","shell.execute_reply.started":"2022-12-31T10:33:45.142112Z","shell.execute_reply":"2022-12-31T10:33:56.672467Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"test on cuda:0\ntest over!\n","output_type":"stream"}]}]}