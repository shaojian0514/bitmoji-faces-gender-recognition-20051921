{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-30T20:41:49.605950Z","iopub.execute_input":"2022-12-30T20:41:49.606621Z","iopub.status.idle":"2022-12-30T20:41:49.626542Z","shell.execute_reply.started":"2022-12-30T20:41:49.606547Z","shell.execute_reply":"2022-12-30T20:41:49.625678Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport math\nimport torch.optim as optim\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n# This SEModule is not used.\nclass SEModule(nn.Module):\n\n    def __init__(self, planes, compress_rate):\n        super(SEModule, self).__init__()\n        self.conv1 = nn.Conv2d(planes, planes // compress_rate, kernel_size=1, stride=1, bias=True)\n        self.conv2 = nn.Conv2d(planes // compress_rate, planes, kernel_size=1, stride=1, bias=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        module_input = x\n        x = F.avg_pool2d(module_input, kernel_size=module_input.size(2))\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.sigmoid(x)\n        return module_input * x\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass SENet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000, include_top=True):\n        self.inplanes = 64\n        super(SENet, self).__init__()\n        self.include_top = include_top\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        \n        if not self.include_top:\n            return x\n        \n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\ndef senet18(num_classes):\n    model = SENet(BasicBlock, [2, 2, 2, 2],num_classes=num_classes)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-30T20:41:58.462200Z","iopub.execute_input":"2022-12-30T20:41:58.462806Z","iopub.status.idle":"2022-12-30T20:41:59.973209Z","shell.execute_reply.started":"2022-12-30T20:41:58.462772Z","shell.execute_reply":"2022-12-30T20:41:59.971872Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\n\n#建立自己的dataset train_data\nclass MyDataset(Dataset):\n    def __init__(self, image_path: list, image_class: list, transform=None):\n        self.image_path = image_path\n        self.image_class = image_class\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_path)\n\n    def __getitem__(self, item):\n        img = Image.open(self.image_path[item]).convert('RGB')\n#         if img.mode != 'RGB':\n#             raise ValueError(\"image: {} isn't RGB mode\".format(self.image_path[item]))\n        label = self.image_class[item]\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2022-12-30T20:42:06.672094Z","iopub.execute_input":"2022-12-30T20:42:06.672598Z","iopub.status.idle":"2022-12-30T20:42:06.866171Z","shell.execute_reply.started":"2022-12-30T20:42:06.672564Z","shell.execute_reply":"2022-12-30T20:42:06.865172Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom torch.autograd import Variable\n\nepoch_num=20\nbatch_size=128\nlr=0.0003\npath_photo='/kaggle/input/bitmojidataset/trainimages'\npath_label='/kaggle/input/bitmojidataset/train.csv'\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224))\n])\n\n# temp_name = os.listdir(path_photo)\ndf=pd.read_csv(path_label)\nimage_path=[]\nlabel_path = []\nfor dir in os.listdir(path_photo):\n#     print(dir)\n    image_path.append(path_photo+'/'+str(dir))\n    # 得到所有图片label\n    if df[df.image_id == dir].iloc[0, 1]==-1:\n        label_path.append(0)\n    else:\n        label_path.append(df[df.image_id == dir].iloc[0, 1])\n\nimage_path=np.array(image_path)\nlabel_path=np.array(label_path)\n\ntrain_path,val_path,train_label,val_label=train_test_split(image_path,label_path,test_size=0.2,random_state=1)\n# print(len(train_path),len(val_path))\ntrain_data=MyDataset(train_path,train_label,transform)\nval_data=MyDataset(val_path,val_label,transform)\ntrain_loader = DataLoader(train_data, batch_size, shuffle=False)\nval_loader = DataLoader(val_data, batch_size,shuffle=False)\nprint(train_loader)\nprint(val_loader)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T20:42:10.676430Z","iopub.execute_input":"2022-12-30T20:42:10.676782Z","iopub.status.idle":"2022-12-30T20:42:13.618935Z","shell.execute_reply.started":"2022-12-30T20:42:10.676753Z","shell.execute_reply":"2022-12-30T20:42:13.617932Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<torch.utils.data.dataloader.DataLoader object at 0x7f8f6f491b10>\n<torch.utils.data.dataloader.DataLoader object at 0x7f8f6e361910>\n","output_type":"stream"}]},{"cell_type":"code","source":"net=senet18(num_classes=2)\nif torch.cuda.is_available():\n    net.cuda()\ncriterion=nn.CrossEntropyLoss()\noptimizer=optim.Adam(net.parameters(), lr=lr)\n# 参数量\nn_p=sum(x.numel() for x in net.parameters())\nprint(n_p)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T20:42:17.255641Z","iopub.execute_input":"2022-12-30T20:42:17.256090Z","iopub.status.idle":"2022-12-30T20:42:21.241013Z","shell.execute_reply.started":"2022-12-30T20:42:17.256050Z","shell.execute_reply":"2022-12-30T20:42:21.240105Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"11177538\n","output_type":"stream"}]},{"cell_type":"code","source":"# 训练\nimport time\n# iter=0\nloss=0\nacc=0\nn=0\nprint('start training!')\nstart=time.time()\nfor epoch in range(epoch_num):\n    for img,label in train_loader:\n        # 将数据移到GPU上\n        img=img.cuda()\n        label=label.cuda()\n        # 先将optimizer梯度先置为0\n        optimizer.zero_grad()\n        out=net(img)\n        # 计算loss,图的终点处\n        loss0=criterion(out,label)\n        loss=loss0\n\n#         反向传播\n        loss.backward()\n        # 更新参数\n        optimizer.step()\n        prect =out.argmax(1)\n        num_correct=(prect==label).sum()\n        acc+=num_correct.item()\n        n+=label.shape[0]\n    print('epoch: {}, loss: {:.4} Acc: {:.6f}'.format(epoch, loss.data.item(),acc / n))\n\nstart= time.time()-start\nprint(start)\nprint(\"train over!\")\nif not os.path.exists('./model_save'):\n    os.mkdir('./model_save')\ntorch.save(net.state_dict,os.path.join('./model_save/','epoch_{}_.pth'.format(epoch+1)))","metadata":{"execution":{"iopub.status.busy":"2022-12-30T20:48:25.653236Z","iopub.execute_input":"2022-12-30T20:48:25.654154Z","iopub.status.idle":"2022-12-30T20:54:06.056595Z","shell.execute_reply.started":"2022-12-30T20:48:25.654121Z","shell.execute_reply":"2022-12-30T20:54:06.055555Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"start training!\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 0, loss: 0.04438 Acc: 0.928750\nepoch: 1, loss: 0.007823 Acc: 0.961042\nepoch: 2, loss: 0.0007669 Acc: 0.973611\nepoch: 3, loss: 0.0005692 Acc: 0.980208\nepoch: 4, loss: 0.002044 Acc: 0.984083\nepoch: 5, loss: 0.0009296 Acc: 0.986667\nepoch: 6, loss: 0.0002263 Acc: 0.988571\nepoch: 7, loss: 0.0001589 Acc: 0.990000\nepoch: 8, loss: 0.0001299 Acc: 0.991111\nepoch: 9, loss: 0.0001098 Acc: 0.992000\nepoch: 10, loss: 9.57e-05 Acc: 0.992727\nepoch: 11, loss: 8.496e-05 Acc: 0.993333\nepoch: 12, loss: 7.635e-05 Acc: 0.993846\nepoch: 13, loss: 6.92e-05 Acc: 0.994286\nepoch: 14, loss: 6.317e-05 Acc: 0.994667\nepoch: 15, loss: 5.801e-05 Acc: 0.995000\nepoch: 16, loss: 5.353e-05 Acc: 0.995294\nepoch: 17, loss: 4.962e-05 Acc: 0.995556\nepoch: 18, loss: 4.616e-05 Acc: 0.995789\nepoch: 19, loss: 4.311e-05 Acc: 0.996000\n340.3100345134735\ntrain over!\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n# 模型评估\nnet.eval()\neval_loss=0\neval_acc=0\nfor img,label in val_loader:\n    if torch.cuda.is_available():\n        img=img.cuda()\n        label=label.cuda()\n    out=net(img)\n    loss=criterion(out,label)\n    eval_loss+=loss.item()*label.size(0)\n    prect =out.argmax(1)\n    num_correct=(prect==label).sum()\n    eval_acc+=num_correct.item()\nprint('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(val_data)), eval_acc / (len(val_data))))\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-30T20:54:19.707842Z","iopub.execute_input":"2022-12-30T20:54:19.708811Z","iopub.status.idle":"2022-12-30T20:54:24.658207Z","shell.execute_reply.started":"2022-12-30T20:54:19.708762Z","shell.execute_reply":"2022-12-30T20:54:24.657101Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Test Loss: 0.014680, Acc: 0.995000\n","output_type":"stream"}]},{"cell_type":"code","source":"# 测试\nimport torch\nimport pandas as pd\ntestimg_path='/kaggle/input/bitmojidataset/testimages'\nsubmission_path='/kaggle/input/bitmojidataset/sample_submission.csv'\n\ncnt=0\ntest_df=pd.read_csv(submission_path)\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224))\n])\n\n# net.eval()\nwith torch.no_grad():\n    parent_list=os.listdir(testimg_path)\n    parent_list.sort()\n#     print(parent_list)\n    for img_name in parent_list:\n        img_path = os.path.join(testimg_path, img_name)\n        img = Image.open(img_path).convert('RGB')\n        img = transform(img)\n        if torch.cuda.is_available():\n            img=img.cuda()\n        img = img.unsqueeze(0)\n        prect = int(net(img).argmax(1))\n        if prect==0:\n            prect=-1\n#         print(prect)\n        test_df['is_male'].iloc[cnt:cnt+1]=str(prect)\n        cnt+=1\n# test_df.iloc[:,1:2]\nprint(test_df)    \ntest_df.to_csv('./sample_submission.csv',index=False,header=True)\nprint('test_over!')","metadata":{"execution":{"iopub.status.busy":"2022-12-30T20:55:21.114021Z","iopub.execute_input":"2022-12-30T20:55:21.114406Z","iopub.status.idle":"2022-12-30T20:55:32.965532Z","shell.execute_reply.started":"2022-12-30T20:55:21.114374Z","shell.execute_reply":"2022-12-30T20:55:32.964466Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_block(indexer, value, name)\n","output_type":"stream"},{"name":"stdout","text":"      image_id is_male  left_eye_x  left_eye_y  right_eye_x  right_eye_y  \\\n0     3000.jpg      -1       152.0       198.0        233.0        195.0   \n1     3001.jpg      -1         NaN         NaN          NaN          NaN   \n2     3002.jpg      -1         NaN         NaN          NaN          NaN   \n3     3003.jpg       1         NaN         NaN          NaN          NaN   \n4     3004.jpg      -1         NaN         NaN          NaN          NaN   \n...        ...     ...         ...         ...          ...          ...   \n1079  4079.jpg      -1         NaN         NaN          NaN          NaN   \n1080  4080.jpg       1         NaN         NaN          NaN          NaN   \n1081  4081.jpg       1         NaN         NaN          NaN          NaN   \n1082  4082.jpg      -1         NaN         NaN          NaN          NaN   \n1083  4083.jpg       1         NaN         NaN          NaN          NaN   \n\n      nose_x  nose_y  mouth_left_x  mouth_left_y  mouth_right_x  mouth_right_y  \n0      192.0   235.0         157.0         264.0          227.0          262.0  \n1        NaN     NaN           NaN           NaN            NaN            NaN  \n2        NaN     NaN           NaN           NaN            NaN            NaN  \n3        NaN     NaN           NaN           NaN            NaN            NaN  \n4        NaN     NaN           NaN           NaN            NaN            NaN  \n...      ...     ...           ...           ...            ...            ...  \n1079     NaN     NaN           NaN           NaN            NaN            NaN  \n1080     NaN     NaN           NaN           NaN            NaN            NaN  \n1081     NaN     NaN           NaN           NaN            NaN            NaN  \n1082     NaN     NaN           NaN           NaN            NaN            NaN  \n1083     NaN     NaN           NaN           NaN            NaN            NaN  \n\n[1084 rows x 12 columns]\ntest_over!\n","output_type":"stream"}]}]}